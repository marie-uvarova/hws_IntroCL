### Задание 1 (5 баллов).

Ответьте на следующие вопросы (по возможности своими словами, а не копипастой):

1. Приведите классификацию формальных грамматик Хомского с примерами для категорий 2 и 3.

Всего выделяется 4 вида грамматик в зависимости от ограничений, которые применены к их правилам:
Тип 0. На правила не накладывается никаких дополнительных ограничений. Любая порождающая грамматика является грамматикой типа 0.
Тип 1. Контекстно-зависимая грамматика: левая часть может содержать один нетерминал, окруженный «контекстом» (последовательности символов, в том же виде присутствующие в правой части); сам нетерминал заменяется непустой последовательностью символов в правой части.
Тип 2. Контекстно-свободная грамматика: левые части являются одиночными нетерминалами
Sentence → NP + VP
NP → T + N
VP → Verb + NP
T → the
N → man, ball etc.
Verb → hit, took etc.

Sentence
NP + VP
T + N + VP
T + N + Verb + NP
the + N + Verb + NP
the + man + Verb + NP
the + man + hit + NP
the + man + hit + T + N
the + man + hit + the + N

the + man + hit + the + ball

Пример: синтаксис ЯП ALGOL 60: 
<statement> → <unconditional statement> | <conditional statement>
<unconditional statement> → <for statement>
<conditional statement> → <if statement> | <if statement> else <statement>
<if statement> → <if clause> <unconditional statement>
<if clause> → if <boolean expression> then

Тип 3. Регулярная грамматика: должна иметь один нетерминал с левой стороны и правую сторону, состоящую из одного
терминала или одного терминала, за которым следует один нетерминал

Пример: язык регулярных выражений

2. Что такое бейзлайн, пайплайн, SOTA? Приведите примеры.

Бейзлайн - уже существующее базовое, простое решение задачи
Пайплайн - инструмент, который автоматизирует процесс работы с данными. Он предобрабатывает их и обучает, тестирует и оценивает модель. Из конспекта: "набор действий, которые нужно выполнить, чтобы решить какую-нибудь задачу".
SOTA - решение задачи, обладающее лучшими оценками по метрикам, которые релевантны в нашей задаче

Пример: задача классификации текстов.
Бейзлайн - TF-IDF + логистическая регрессия
Пайплайн - 
1. Разметка данных
2. Обработка данных
3. Выбор модели классификации
4. Применение модели
5. Оценка качества
SOTA - DeBERTa, XLNet

3. Какие элементы имплементации регулярного языка PCRE не являются собственно элементами грамматики регулярного языка по классификации Хомского?

Проверки (lookarounds: positive/negative lookahead/lookbehind)

4. Что такое языковая модель? Какие типы языковых моделей вы знаете?

Языковая модель ― алгоритм, который позволяет вычислить вероятностное распределение слов в текстах. Он нужен для понимания и генерации контента на естественном языке.
Типы:
1. Статистические:
    e. g. N-граммные модели
2. Нейросетевые
3. LLM (Large Language Model)
4. Pre-Trained Language Models

5. Чем задача классификации отличается от задачи кластеризации?

При классификации категории, к которым объекты должны быть отнесены, определены заранее, при кластеризации они не заданы и также может отсутствовать информация об их количестве


### Задание 2 (10 баллов). 

Попробуйте самостоятельно разработать метрики для оценки качества автоматического морфологического анализа: как бы вы оценивали качество лемматизации, приписывания частей речи и морфологических характеристик? Подумайте, какие вещи необходимо учесть. В результате у вас должны получиться три формулы, в которых будут фигурировать y_true (правильные ответы) и y_pred (предсказанные парсером ответы). Для морфологических признаков ответ явно будет складываться из нескольких категорий, например, род, число и падеж, нужно это учесть. Опишите словами ход своих рассуждений, приведите аргументы. Можно отталкиваться от уже существующих метрик, но если берете готовые, нужно их проанализировать.

### Задание 3 (10 баллов). 

Выберите любую понравившуюся вам задачу NLP и исследуйте литературу по этой задаче. Какой у нее бейзлайн? Какая SOTA? В каком направлении ведутся современные исследования, связанные с этой задачей? Какие практические применения? Напишите коротенький конспект. 

Рекомендация: попробуйте искать survey - статьи на scholar.google.com.

Разрешение кореференции событий.

Пример:
Georges Cipriani {left}ev1 a prison in Ensisheim in northern France on parole on Wednesday. He {departed}ev2 the prison in a police vehicle bound for an open prison near Strasbourg.

ev1 и ev2 считаются кореферентными, так как обозначают одну ситуацию: Киприани покидает тюрьму.

Чтобы два считать события кореферентными, они должны 
1) иметь один и тот же подтип события
2) их аргументы должны быть совместимыми
В данном случае ev1 и ev2 имеют один и тот же подтип Movement.Transport-Person.

Где используется РКС?
1) Automated population of knowledge bases
2) Template filling
3) Question answering
4) Contradiction detection
5) Topic detection

Бейзлайны:
1. Multi-Pass Sieve [Lu and Ng, 2016] итеративный pipeline-based метод, который использует как созданные вручную правила, так и автоматические классификаторы.
2. Mention Ranking [Lu and Ng, 2017b] ранжирует потенциальные антецеденты всех упоминаний о событии и выбирает антецедента с самым высоким рейтингом для каждого упоминания.
3. Joint Model [Lu and Ng, 2017a] система, которая при помощи одновременного изучения задач обнаружения триггеров событий, разрешения корреференции событий и прогнозирования анафоричности событий решает проблему распространения ошибок
4. Interact Model [Huang et al., 2019] - метод, в котором кореференция определяется при помощи интерактивного двоичного классификатора. Затем кореф. события связываются корреференциальными упоминаниями для создания окончательных цепочек событий

Пример бейзлайна ('pipeline-based baseline system'), приведенный в [Lu & Ng 2017]:
Step 1: Entity extraction.
Step 2: Entity coreference resolution.
Step 3: Trigger identification and subtyping.
Step 4: Argument identification and role labeling.
Step 5: Event coreference resolution.

Пример SOTA:
E3C neural network [Lu et al. 2022]

Пример дальнейшее развитие: 
1. Продолжить исследование joint model и его использования в задачах information extraction
2. Изучить, существуют ли проблемы, специфичные для языка, которые могут повлиять на эффективное применение различных походов к применению аннотаций для разрешения кореференций событий с участием менее изученных языков. Кроме того, если для целевого языка не существует больших баз лексических знаний, было бы важно изучить альтернативные методы получения семантических знаний.

Литература:
Liu et al. 2023. A brief survey on recent advances in coreference resolution.

Lu and Ng, 2017a Jing Lu and Vincent Ng. Joint learning for event coreference resolution. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 90–101, 2017.

Lu and Ng, 2017b Jing Lu and Vincent Ng. Learning antecedent structures for event coreference resolution. In Proceedings of the 16th IEEE International Conference on Machine Learning and Applications, pages 113–118, 2017.

Lu, Y., Lin, H., Tang, J., Han, X., & Sun, L. 2022. End-to-end neural event coreference resolution. Artificial Intelligence, 303, 103632.

### Задание 4 (15 баллов). 

Возьмите любой достаточно большой conll-файл и проведите мини-исследование, связанное с дативно-предикативными конструкциями (такими, как "мне холодно" и "сегодня холодно": предикативы такого рода могут присоединять дополнение в дат.п., а могут не присоединять), по [статье](https://www.dialog-21.ru/media/5937/zimmerlingav120.pdf) А.В. Циммерлинга. Вам понадобится написать скрипт, в котором будут автоматически рассчитываться метрики, приведенные Циммерлингом в своей статье. Придется учесть, что в формате UD нет части речи "предикатив" (можно посчитать метрики только для n верхних предикативов в его таблице - это будут конкретные слова), и подумать о том, как собирать все зависимые для текущего проверяемого токена. Советую взять Синтагрус (либо можно разобрать свои собственные тексты, но если будет их слишком мало, у вас метрики будут близки к нулю или просто нули). Для части группы, которая умеет писать код в классах, настойчиво советую оформить это в класс. 
